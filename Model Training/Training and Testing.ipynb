{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have chosen 5 ML Algorithms namely:\n",
    "\n",
    "\n",
    "1. Naive Bayes\n",
    "2. Stochastic Gradient Descent\n",
    "3. Logistic Regression\n",
    "4. Random Forest\n",
    "5. Linear Suport Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following is the list of flairs selected\n",
    "\n",
    "flairs=[\"[R]eddiquette\",\"Politics\",\"Non-Political\",\"Business/Finance\",\"Unverified\",\"Science/Technology\",\"Sports\",\"Photography\",\"CAA-NRC\",\"Food\",\"AskIndia\",\"Policy/Economy\",\"Scheduled\",\"AMA\",\"Coronavirus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Stopwords.csv')\n",
    "data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>no_comm</th>\n",
       "      <th>body</th>\n",
       "      <th>comment</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"men\", \"thirty\", \"decided\", \"get\", \"married\",...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>206</td>\n",
       "      <td>[\"corona\", \"virus\", \"given\", \"time\", \"think\", ...</td>\n",
       "      <td>[\"plan\", \"finances\", \"work\", \"enjoy\", \"ways\", ...</td>\n",
       "      <td>AskIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"imfs\", \"nineteen\", \"growth\", \"prediction\", \"...</td>\n",
       "      <td>https://www.youtube.com/watch?v=QdGEw_JCZkc</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>[\"karan\", \"thapar\", \"journalist\", \"made\", \"god...</td>\n",
       "      <td>Policy/Economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  [\"men\", \"thirty\", \"decided\", \"get\", \"married\",...   \n",
       "1  [\"imfs\", \"nineteen\", \"growth\", \"prediction\", \"...   \n",
       "\n",
       "                                                 url  no_comm  \\\n",
       "0  https://www.reddit.com/r/india/comments/fvy95j...      206   \n",
       "1        https://www.youtube.com/watch?v=QdGEw_JCZkc        4   \n",
       "\n",
       "                                                body  \\\n",
       "0  [\"corona\", \"virus\", \"given\", \"time\", \"think\", ...   \n",
       "1                                                      \n",
       "\n",
       "                                             comment           flair  \n",
       "0  [\"plan\", \"finances\", \"work\", \"enjoy\", \"ways\", ...        AskIndia  \n",
       "1  [\"karan\", \"thapar\", \"journalist\", \"made\", \"god...  Policy/Economy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  I have created a new column in my data 'combined'  which holds the values for columns combined from title, url , comment which gave me the highest accuracy levels, about 70% using the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined']=data['title']+\",\"+data['url']+\",\"+data['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [\"men\", \"thirty\", \"decided\", \"get\", \"married\",...\n",
      "1       [\"imfs\", \"nineteen\", \"growth\", \"prediction\", \"...\n",
      "2       [\"roasted\", \"chicken\", \"veggies\"],https://i.re...\n",
      "3       [\"khan\", \"academy\", \"helped\", \"many\", \"us\", \"u...\n",
      "4       [\"world\", \"learn\", \"kerala\", \"fight\", \"covid19...\n",
      "                              ...                        \n",
      "1495    [\"cop\", \"\\u2019\", \"hand\", \"chopped\", \"two\", \"o...\n",
      "1496    [\"clashes\", \"erupt\", \"kashmir\", \"first\", \"civi...\n",
      "1497    [\"video\", \"mosque\", \"vandalised\", \"set\", \"fire...\n",
      "1498    [\"mobile\", \"internet\", \"speed\", \"slow\", \"india...\n",
      "1499    [\"twitter\", \"suspends\", \"kangana\", \"ranauts\", ...\n",
      "Name: combined, Length: 1500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "arr = data['combined']\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = data['combined']\n",
    "cnt=0\n",
    "for ele in arr:\n",
    "    a1=''\n",
    "    a = str(ele).split(',')\n",
    "    for item in a:\n",
    "        item1 = item.replace(\"[\",'')\n",
    "        item1 = item1.replace(\"]\",'')\n",
    "        item1 = item1.replace('\"','')\n",
    "        item1 = item1.replace(' ','')\n",
    "        a1=a1+\",\"+(item1)\n",
    "        data.at[cnt,'combined']=a1\n",
    "    cnt=cnt+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       ,men,thirty,decided,get,married,plan,old,age,h...\n",
      "1       ,imfs,nineteen,growth,prediction,india,ludicro...\n",
      "2       ,roasted,chicken,veggies,https://i.redd.it/eyt...\n",
      "3       ,khan,academy,helped,many,us,understand,chapte...\n",
      "4       ,world,learn,kerala,fight,covid19,https://www....\n",
      "                              ...                        \n",
      "1495    ,cop,\\u2019,hand,chopped,two,others,injured,at...\n",
      "1496    ,clashes,erupt,kashmir,first,civilian,death,co...\n",
      "1497    ,video,mosque,vandalised,set,fire,ashok,nagar,...\n",
      "1498    ,mobile,internet,speed,slow,india,pakistan,nep...\n",
      "1499    ,twitter,suspends,kangana,ranauts,sister,rango...\n",
      "Name: combined, Length: 1500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "arr = data['combined']\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>no_comm</th>\n",
       "      <th>body</th>\n",
       "      <th>comment</th>\n",
       "      <th>flair</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"men\", \"thirty\", \"decided\", \"get\", \"married\",...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>206</td>\n",
       "      <td>[\"corona\", \"virus\", \"given\", \"time\", \"think\", ...</td>\n",
       "      <td>[\"plan\", \"finances\", \"work\", \"enjoy\", \"ways\", ...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>,men,thirty,decided,get,married,plan,old,age,h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"imfs\", \"nineteen\", \"growth\", \"prediction\", \"...</td>\n",
       "      <td>https://www.youtube.com/watch?v=QdGEw_JCZkc</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>[\"karan\", \"thapar\", \"journalist\", \"made\", \"god...</td>\n",
       "      <td>Policy/Economy</td>\n",
       "      <td>,imfs,nineteen,growth,prediction,india,ludicro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"roasted\", \"chicken\", \"veggies\"]</td>\n",
       "      <td>https://i.redd.it/eytftqoreda41.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td>[\"removed\", \"looks\", \"juicy\", \"nice\", \"could\",...</td>\n",
       "      <td>Food</td>\n",
       "      <td>,roasted,chicken,veggies,https://i.redd.it/eyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"khan\", \"academy\", \"helped\", \"many\", \"us\", \"u...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fqmz7y...</td>\n",
       "      <td>54</td>\n",
       "      <td>[\"indebted\", \"salmans\", \"efforts\", \"make\", \"bo...</td>\n",
       "      <td>[\"good\", \"see\", \"people\", \"using\", \"khan\", \"ac...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>,khan,academy,helped,many,us,understand,chapte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"world\", \"learn\", \"kerala\", \"fight\", \"covid19\"]</td>\n",
       "      <td>https://www.technologyreview.com/2020/04/13/99...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>,world,learn,kerala,fight,covid19,https://www....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  [\"men\", \"thirty\", \"decided\", \"get\", \"married\",...   \n",
       "1  [\"imfs\", \"nineteen\", \"growth\", \"prediction\", \"...   \n",
       "2                  [\"roasted\", \"chicken\", \"veggies\"]   \n",
       "3  [\"khan\", \"academy\", \"helped\", \"many\", \"us\", \"u...   \n",
       "4   [\"world\", \"learn\", \"kerala\", \"fight\", \"covid19\"]   \n",
       "\n",
       "                                                 url  no_comm  \\\n",
       "0  https://www.reddit.com/r/india/comments/fvy95j...      206   \n",
       "1        https://www.youtube.com/watch?v=QdGEw_JCZkc        4   \n",
       "2                https://i.redd.it/eytftqoreda41.jpg       20   \n",
       "3  https://www.reddit.com/r/india/comments/fqmz7y...       54   \n",
       "4  https://www.technologyreview.com/2020/04/13/99...        0   \n",
       "\n",
       "                                                body  \\\n",
       "0  [\"corona\", \"virus\", \"given\", \"time\", \"think\", ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  [\"indebted\", \"salmans\", \"efforts\", \"make\", \"bo...   \n",
       "4                                                      \n",
       "\n",
       "                                             comment           flair  \\\n",
       "0  [\"plan\", \"finances\", \"work\", \"enjoy\", \"ways\", ...        AskIndia   \n",
       "1  [\"karan\", \"thapar\", \"journalist\", \"made\", \"god...  Policy/Economy   \n",
       "2  [\"removed\", \"looks\", \"juicy\", \"nice\", \"could\",...            Food   \n",
       "3  [\"good\", \"see\", \"people\", \"using\", \"khan\", \"ac...        AskIndia   \n",
       "4                                                        Coronavirus   \n",
       "\n",
       "                                            combined  \n",
       "0  ,men,thirty,decided,get,married,plan,old,age,h...  \n",
       "1  ,imfs,nineteen,growth,prediction,india,ludicro...  \n",
       "2  ,roasted,chicken,veggies,https://i.redd.it/eyt...  \n",
       "3  ,khan,academy,helped,many,us,understand,chapte...  \n",
       "4  ,world,learn,kerala,fight,covid19,https://www....  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   title     1500 non-null   object\n",
      " 1   url       1500 non-null   object\n",
      " 2   no_comm   1500 non-null   int64 \n",
      " 3   body      1500 non-null   object\n",
      " 4   comment   1500 non-null   object\n",
      " 5   flair     1500 non-null   object\n",
      " 6   combined  1500 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 82.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Here I have set up the training and testing variables for my algorithm. Finally I chose a 9:1 training and testing ratio as it provided me with the highest accuracy results.\n",
    "\n",
    "I started off with a 8:2 split and the results were about 45% - 50% and then I started tweaking the split and finally settled for a 9:1 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent and independent variables\n",
    "y = data.flair\n",
    "X = data.combined\n",
    "\n",
    "#Setting training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Using a Pipeline function combines the CountVetorizer command which cleans the data, the TfidfTransformer which computes word counts etc. and finally the Regression Model Command into single easy to understand command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.5466666666666666\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     [R]eddiquette       0.24      1.00      0.39         7\n",
      "          Politics       0.21      0.50      0.29        10\n",
      "     Non-Political       1.00      0.33      0.50        12\n",
      "  Business/Finance       0.38      0.83      0.53         6\n",
      "        Unverified       1.00      0.58      0.74        12\n",
      "Science/Technology       1.00      0.67      0.80         9\n",
      "            Sports       0.00      0.00      0.00         9\n",
      "       Photography       1.00      0.83      0.91        12\n",
      "           CAA-NRC       0.20      0.40      0.27         5\n",
      "              Food       0.67      0.62      0.64        13\n",
      "          AskIndia       0.93      1.00      0.97        14\n",
      "    Policy/Economy       1.00      0.14      0.25         7\n",
      "         Scheduled       0.89      0.67      0.76        12\n",
      "               AMA       1.00      0.09      0.17        11\n",
      "       Coronavirus       0.67      0.36      0.47        11\n",
      "\n",
      "          accuracy                           0.55       150\n",
      "         macro avg       0.68      0.54      0.51       150\n",
      "      weighted avg       0.73      0.55      0.55       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "NB = nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy is \"+str(accuracy_score(y_pred, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.64\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     [R]eddiquette       0.70      1.00      0.82         7\n",
      "          Politics       0.38      0.50      0.43        10\n",
      "     Non-Political       0.75      0.50      0.60        12\n",
      "  Business/Finance       0.42      0.83      0.56         6\n",
      "        Unverified       0.77      0.83      0.80        12\n",
      "Science/Technology       0.56      0.56      0.56         9\n",
      "            Sports       0.67      0.22      0.33         9\n",
      "       Photography       0.63      1.00      0.77        12\n",
      "           CAA-NRC       0.43      0.60      0.50         5\n",
      "              Food       0.62      0.62      0.62        13\n",
      "          AskIndia       0.88      1.00      0.93        14\n",
      "    Policy/Economy       0.75      0.43      0.55         7\n",
      "         Scheduled       0.92      0.92      0.92        12\n",
      "               AMA       0.33      0.09      0.14        11\n",
      "       Coronavirus       0.50      0.36      0.42        11\n",
      "\n",
      "          accuracy                           0.64       150\n",
      "         macro avg       0.62      0.63      0.60       150\n",
      "      weighted avg       0.64      0.64      0.61       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "SGD = sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(\"Accuracy is \"+str(accuracy_score(y_pred, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  As the Logistic Regression Model had the largest accuracy for the 9:1 split, I selected the following model and the model for saved using the pickle function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6933333333333334\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     [R]eddiquette       1.00      1.00      1.00         7\n",
      "          Politics       0.29      0.40      0.33        10\n",
      "     Non-Political       0.86      0.50      0.63        12\n",
      "  Business/Finance       0.71      0.83      0.77         6\n",
      "        Unverified       0.91      0.83      0.87        12\n",
      "Science/Technology       0.75      0.67      0.71         9\n",
      "            Sports       0.57      0.44      0.50         9\n",
      "       Photography       0.85      0.92      0.88        12\n",
      "           CAA-NRC       0.40      0.80      0.53         5\n",
      "              Food       0.67      0.62      0.64        13\n",
      "          AskIndia       0.93      0.93      0.93        14\n",
      "    Policy/Economy       0.75      0.86      0.80         7\n",
      "         Scheduled       0.92      0.92      0.92        12\n",
      "               AMA       0.50      0.45      0.48        11\n",
      "       Coronavirus       0.40      0.36      0.38        11\n",
      "\n",
      "          accuracy                           0.69       150\n",
      "         macro avg       0.70      0.70      0.69       150\n",
      "      weighted avg       0.71      0.69      0.70       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e20)),\n",
    "               ])\n",
    "LOGREG = logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "pickle.dump(LOGREG,open('model_final.pkl','wb'))\n",
    "print(\"Accuracy is \"+str(accuracy_score(y_pred, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.5933333333333334\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     [R]eddiquette       0.64      1.00      0.78         7\n",
      "          Politics       0.33      0.50      0.40        10\n",
      "     Non-Political       0.56      0.42      0.48        12\n",
      "  Business/Finance       0.36      0.83      0.50         6\n",
      "        Unverified       0.60      0.75      0.67        12\n",
      "Science/Technology       0.50      0.22      0.31         9\n",
      "            Sports       0.60      0.33      0.43         9\n",
      "       Photography       0.53      0.83      0.65        12\n",
      "           CAA-NRC       0.33      0.40      0.36         5\n",
      "              Food       0.70      0.54      0.61        13\n",
      "          AskIndia       0.93      1.00      0.97        14\n",
      "    Policy/Economy       0.56      0.71      0.63         7\n",
      "         Scheduled       0.86      1.00      0.92        12\n",
      "               AMA       0.50      0.09      0.15        11\n",
      "       Coronavirus       1.00      0.18      0.31        11\n",
      "\n",
      "          accuracy                           0.59       150\n",
      "         macro avg       0.60      0.59      0.54       150\n",
      "      weighted avg       0.63      0.59      0.56       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "ranfor = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 5)),\n",
    "                  ])\n",
    "RM = ranfor.fit(X_train, y_train)\n",
    "#pickle.dump(RM,open(\"model_RM.sav\",'wb'))\n",
    "y_pred = ranfor.predict(X_test)\n",
    "\n",
    "print(\"Accuracy is \"+str(accuracy_score(y_pred, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6866666666666666\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     [R]eddiquette       1.00      1.00      1.00         7\n",
      "          Politics       0.29      0.40      0.33        10\n",
      "     Non-Political       0.75      0.50      0.60        12\n",
      "  Business/Finance       0.62      0.83      0.71         6\n",
      "        Unverified       0.77      0.83      0.80        12\n",
      "Science/Technology       0.75      0.67      0.71         9\n",
      "            Sports       0.71      0.56      0.63         9\n",
      "       Photography       0.79      0.92      0.85        12\n",
      "           CAA-NRC       0.29      0.40      0.33         5\n",
      "              Food       0.69      0.69      0.69        13\n",
      "          AskIndia       0.93      1.00      0.97        14\n",
      "    Policy/Economy       0.46      0.86      0.60         7\n",
      "         Scheduled       1.00      0.83      0.91        12\n",
      "               AMA       0.57      0.36      0.44        11\n",
      "       Coronavirus       0.67      0.36      0.47        11\n",
      "\n",
      "          accuracy                           0.69       150\n",
      "         macro avg       0.69      0.68      0.67       150\n",
      "      weighted avg       0.71      0.69      0.69       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm1 = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', svm.SVC(kernel='linear', C=1.0)),\n",
    "               ])\n",
    "SVM = svm1.fit(X_train, y_train)\n",
    "y_pred = svm1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy is \"+str(accuracy_score(y_pred, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
